chromedriver.chromium.org/downloads

import selenium
from selenium import webdriver
import pandas as pd
from selenium.webdriver.common.by import By
import warnings
warnings.filterwarnings("ignore")
import time

driver=webdriver.Chrome()
driver.get("https://www.naukri.com")

designation = driver.find_element(By.CLASS_NAME,"suggestor-input")
designation.send_keys("Data Analyst")

location = driver.find_element(By.XPATH,"/html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input")
location.send_keys("Banglore")

search = driver.find_element(By.CLASS_NAME,"qsbSubmit")
search.click()

job_title = []
job_location = []
company_name = []
experience_required = []

# Scrapping the job titles from given page

title_tags = driver.find_elements(By.XPATH,'//a[@class="title ellipsis"]')
for i in title_tags[0:10]:
    title=i.text
    job_title.append(title)

# Scrapping the job location from given page

location_tags = driver.find_elements(By.XPATH,'//span[@title="Bangalore/Bengaluru "]')
for i in location_tags[0:10]:
    location=i.text
    job_location.append(location)

#Scrapping the company name from given page

company_tags = driver.find_elements(By.XPATH,'//a[@class="subTitle ellipsis fleft"]')
for i in company_tags[0:10]:
    company=i.text
    company_name.append(company)

#Scrapping the job experience from given page

experince_tags = driver.find_elements(By.XPATH,'//span[@class="ellipsis fleft expwdth"]')
for i in experince_tags[0:10]:
    experience=i.text
    experience_required.append(experience)

print(len(job_title),len(job_location),len(company_name),len(experience_required))

import pandas as pd
df=pd.DataFrame({'Title':job_title, 'Location':job_location,'Company Name':company_name,'Experience':experience_required})
df

job_titles=[]

start=0
end=2

for page in range(start,end):
    title_tags = driver.find_elements(By.XPATH,'//a[@class="title ellipsis"]')
    for i in title_tags[0:10]:
        title=i.text
        job_title.append(title)

    next_button = driver.find_element(By.XPATH,'//a[@class="fright fs14 btn-secondary br2"]')
    next_button.click()
    time.sleep(3)

len(job_titles)

job_titles

Que 2) :
Ans :
import selenium
from selenium import webdriver
from selenium.webdriver.common.by import By
import pandas as pd
import warnings
warnings.filterwarnings("ignore")
import time

driver=webdriver.Chrome()
driver.get("https://www.naukri.com")

designation=driver.find_element(By.CLASS_NAME,"suggestor-input ")
designation.send_keys("Data Scientist")

location=driver.find_element(By.XPATH,"/html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input")
location.send_keys("Banglore")

search=driver.find_element(By.CLASS_NAME,"qsbSubmit")
search.click()

job_title = []
job_location = []

# Scrapping the job titles from given page

title_tags = driver.find_elements(By.XPATH,'//a[@class="title ellipsis"]')
for i in title_tags[0:10]:
    title=i.text
    job_title.append(title)

import pandas as pd
df=pd.DataFrame({'Title':job_title})
df


driver=webdriver.Chrome()
driver.get("https://www.naukri.com")

# finding element for job search bar
search_job = driver.find_element_by_xpath("//input[@class='sugInp']")
search_job

search_job.send_keys('Data Scientist')

# finding element for job location bar
search_loc=driver.find_element_by_id('qsb-location-sugg')
search_loc.send_keys("Bangalore")

search_btn= driver .find_element_by_xpath("//button[@class='btn']")
search_btn

search_btn=driver.find_element_by_class_name('btn')
search_btn.click()

#so let's extract all the tags having the job titles
title_tag=driver.find_elements_by_xpath("//a[@class='title fw500 ellipsis']")
title_tag

job1_titles=[]
for i in title_tag:
    if i.text is None:
        job1_titles.append('Not')
    else:
        job1_titles.append(i.text)
job1_titles[:10] 

company_tag=driver.find_elements_by_xpath("//a[@class='subTitle ellipsis fleft']")
company_tag

companies1_names=[]

for i in company_tag:
    companies1_names.append(i.text)
companies1_names[:10] 

locations_tag=driver.find_elements_by_xpath("//li[@class='fleft grey-text br2 placeHolderLi location']/span")
locations_tag

locations1_list=[]
for i in locations_tag:
    locations1_list.append(i.text)
locations1_list[:10] 

print(len(job1_titles[:10])),print(len(companies1_names[:10])),print(len(locations1_list[:10]))


Que 3)
Ans : 

driver=webdriver.Chrome()
driver.get("https://www.naukri.com")

# finding element for job search bar
search_job = driver.find_element_by_xpath("//input[@class='sugInp']")
search_job
search_job.send_keys('Data Scientist')
search_btn= driver .find_element_by_xpath("//button[@class='btn']")
search_btn

search_btn=driver.find_element_by_class_name('btn')
search_btn.click()

#so let's extract all the tags having the job titles
title_t1=driver.find_elements_by_xpath("//a[@class='title fw500 ellipsis']")
title_t1

job_titles=[]

for i in title_t1:
    if i.text is None:
        job_titles.append('Not')
    else:
        job_titles.append(i.text)
job_titles[:10]

company_t1=driver.find_elements_by_xpath("//a[@class='subTitle ellipsis fleft']")
company_t1

companies_names=[]

for i in company_t1:
    companies_names.append(i.text)
companies_names[:10]

experience_t1=driver.find_elements_by_xpath("//li[@class='fleft grey-text br2 placeHolderLi experience'] //span")
experience_t1

experience_list=[]
for i in experience_t1:
    experience_list.append(i.text)
experience_list[:10]

locations_t1=driver.find_elements_by_xpath("//li[@class='fleft grey-text br2 placeHolderLi location']/span")
locations_t1

locations_list=[]
for i in locations_t1:
    locations_list.append(i.text)
locations_list[:10] 

print(len(job_titles[:10])),print(len(companies_names[:10])),print(len(experience_list[:10])),print(len(locations_list[:10]))

jobs2=pd.DataFrame({})
jobs2['title']=job_titles[:10]
jobs2['company']=companies_names[:10]
jobs2['experience_required']=experience_list[:10]
jobs2['location']=locations_list[:10]
jobs2

Que-4) 

Ans : 

driver=webdriver.Chrome()
driver.get("https://www.flipkart.com")

search_g= driver.find_element_by_xpath("//input[@type='text']")
search_g

search_g.send_keys('sunglasses')

search_btn=driver.find_element_by_xpath("//button[@class='L0Z3Pu']")
search_btn

B_name=[]
Price=[]
P_desc=[]

for i in range(3):
    b_name=driver.find_elements_by_xpath("//div[@class='_2WkVRV']")
    p_desc=driver.find_elements_by_xpath("//a[@class='IRpwTa']")
    price =driver.find_elements_by_xpath("//div[@class='_25b18c']")
    discount=driver.find_elements_by_xpath("//div[@class='_3Ay6Sb']")
    
    for j  in b_name:
        B_name.append(j.text)
    B_name[:100]    
    
    
    
    for k in p_desc:
        P_desc.append(k.text)
    P_desc[:100] 
    
    
    for l in price:
        Price.append(l.text)
    Price[:100] 
   

B_name[:100]
    
print(len(B_name[:100])),print(len(Price[:100])),print(len(P_desc[:100]))

sun_gl=pd.DataFrame({})
sun_gl['Brand_name']=B_name[:100]
sun_gl['P_price']=Price[:100]
sun_gl['Pr_desc']=P_desc[:100]

sun_gl


Que 5) : 
Ans : 

Que-6) : 
Ans : 

driver=webdriver.Chrome()
driver.get("https://www.flipkart.com")

search_g= driver.find_element_by_xpath("//input[@type='text']")
search_g

search_g.send_keys('sneakers')

search_btn=driver.find_element_by_xpath("//button[@class='L0Z3Pu']")
search_btn

search_btn=driver.find_element_by_class_name('L0Z3Pu')
search_btn.click()

B_name=[]
Price=[]
P_desc=[]

for i in range(3):
    b_name=driver.find_elements_by_xpath("//div[@class='_2WkVRV']")
    p_desc=driver.find_elements_by_xpath("//a[@class='IRpwTa']")
    price =driver.find_elements_by_xpath("//div[@class='_25b18c']")
    discount=driver.find_elements_by_xpath("//div[@class='_3Ay6Sb']")
    
    for j  in b_name:
        B_name.append(j.text)
    B_name[:100]    
     
    for k in p_desc:
        P_desc.append(k.text)
    P_desc[:100] 
    
    for l in price:
        Price.append(l.text)
    Price[:100] 
    
print(len(B_name[:100])),print(len(Price[:100])),print(len(P_desc[:100]))

sun_gl=pd.DataFrame({})
sun_gl['Brand_name']=B_name[:100]
sun_gl['P_price']=Price[:100]
sun_gl['Pr_desc']=P_desc[:100]

sun_gl

Que-7)
Ans : 

driver=webdriver.Chrome()
driver.get("https://www.amazon.in")

search_g= driver.find_element_by_xpath("//input[@type='text']")
search_g

search_g.send_keys('Laptop')

search_btn=driver.find_element_by_xpath("//input[@id='nav-search-submit-button']")
search_btn

search_btn=driver.find_element_by_xpath("//input[@id='nav-search-submit-button']")
search_btn.click()

Title=[]
Price=[]
Rating=[]
for i in range(3):
    title_t=driver.find_elements_by_xpath("//div[@class='_2WkVRV']")
    rating=driver.find_elements_by_xpath("//a[@class='IRpwTa']")
    price =driver.find_elements_by_xpath("//div[@class='_25b18c']")
    
    for j  in title_t:
        Title.append(j.text)
    Title[:10]    
    
    for k in rating:
        Rating.append(k.text)
    Rating[:10] 
    
    for l in price:
        Price.append(l.text)
    Price[:10] 
    
print(len(Title[:10])),print(len(Rating[:10])),print(len(Price[:10]))

lap=pd.DataFrame({})
lap['Title'] = Title[:10]
lap['Price'] = Price[:10]
lap['Rating'] = Rating[:10]

lap

